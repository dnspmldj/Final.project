# -*- coding: utf-8 -*-
"""GROUP3_FINAL_PROJECT

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_0mCKxm5kphocRCs-yKHpO-kkQ8nIFKc

# GROUP 3
# FINAL PROJECT IN EMERGING TECHNOLOGIES 2: FASHION DATASET
## Members: <BR>
### **Doroteo, Victor Ponce C.**
### **Echiverri, Syd**
### **De Leon, Sheina Mae**
### **De Jose, Dennisse**
### **Domondon, Mark Stefan**
### INSTRUCTOR:
### **DR. JONATHAN TAYLAR**<BR>
## COURSE/SECTION:
### **CPE019/CPE32S1**

## **IMPORTING MODULES:**
"""

import streamlit as st
import time
from PIL import Image,ImageOps
import numpy as np
import sys
from matplotlib import pyplot
import pandas as pd
from PIL import Image
from numpy import mean
from numpy import std
from numpy import argmax
from matplotlib import pyplot as plt
from sklearn.model_selection import KFold
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dropout
from keras.layers import BatchNormalization
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Dense
from keras.layers import Flatten
from keras.optimizers import SGD
from keras.models import load_model
from keras.utils import load_img
from keras.utils import img_to_array
from keras.utils import to_categorical

@st.cache(allow_output_mutation=True)
def load_model():
  model=tf.keras.models.load_model('saved_fashion.h5')
  return model

def import_and_predict(image_data,model):
    size=(64,64)
    image=ImageOps.fit(image_data,size,Image.ANTIALIAS)
    img=np.asarray(image)
    img_reshape=img[np.newaxis,...]
    prediction=model.predict(img_reshape)
    return prediction

st.write("""# Fasion""")

file=st.file_uploader("Choose clothes photo from computer",type=["jpg","png"])

st.image(image,use_column_width=True)

st.success(string)

"""### **Fashion MNIST Dataset - It contains images of different outfits or those to wear such as shoes, t-shirts, dresses, trousers, boots and many more. It should be able to predict what kind it is when given a test image.**

## **IMPORTING CSV FILE**
"""
  return trainX, valX, testX, trainY, valY, testY

"""### **We have divided the train, test, and validation for this particular section. There are 10,000 photos for testing and 60,000 images for training in the dataset. Following the splitting, a validation set comprising 12,000 rows is produced. After that, the sets are formatted to make them easier to read. It measures 28 by 28.**"""

def summarize_diagnostics(history):
	# plot loss
	pyplot.figure(figsize=(16,10))
	pyplot.subplot(211)
	pyplot.title('Cross Entropy Loss')
	pyplot.plot(history.history['loss'], color='blue', label='train')
	pyplot.plot(history.history['val_loss'], color='orange', label='test')
	# plot accuracy
	pyplot.subplot(212)
	pyplot.title('Classification Accuracy')
	pyplot.plot(history.history['accuracy'], color='blue', label='train')
	pyplot.plot(history.history['val_accuracy'], color='orange', label='test')

# define cnn model
def define_model_3():
	model3 = Sequential()
	model3.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))
	model3.add(BatchNormalization())
	model3.add(Conv2D(32, (3, 3), activation='relu', padding='same'))
	model3.add(BatchNormalization())
	model3.add(MaxPooling2D((2, 2)))
	model3.add(Dropout(0.25))

	model3.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
	model3.add(BatchNormalization())
	model3.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
	model3.add(BatchNormalization())
	model3.add(MaxPooling2D((2, 2)))
	model3.add(Dropout(0.25))

	model3.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
	model3.add(BatchNormalization())
	model3.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
	model3.add(BatchNormalization())
	model3.add(MaxPooling2D((2, 2)))
	model3.add(Dropout(0.25))

	model3.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
	model3.add(BatchNormalization())
	model3.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
	model3.add(BatchNormalization())
	model3.add(MaxPooling2D((2, 2)))
	model3.add(Dropout(0.25))



	model3.add(Flatten())
	model3.add(Dropout(0.25))
	model3.add(Dense(512, activation='relu'))
	model3.add(Dropout(0.25))
	model3.add(Dense(128, activation='relu'))
	model3.add(Dropout(0.25))
	model3.add(Dense(10, activation='softmax'))

	# compile model

	model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
	return model3

early_stop = EarlyStopping(monitor='val_loss', patience=2)

model3= define_model_3()

run_test_harness(model3, 100)

"""### **Finally, a considerably deeper network with three VGG blocks and 512 nodes in the final hidden layer is employed. Each had max norm per block, batch normalization per convolutional layer, and rising dropout rates. Adam was the optimizer, and 100 epochs were utilized. It outperformed the previous two models, as predicted, with 98% accuracy on the dataset and 94% validation. Although there is still some acceptable overfitting, it functioned nicely.**

## **Finalization, saving of model, and testing on new images**
"""

trainX, valX, testX, trainY, valY, testY = prep_pixels(train_X, val_X, test_X, train_Y, val_Y, test_Y)

model3.save('/content/drive/MyDrive/Models/saved_fashion.h5')

model = load_model('/content/drive/MyDrive/Models/saved_fashion.h5')
# evaluate model on test dataset
_, acc = model.evaluate(testX, testY, verbose=0)
print('> %.3f' % (acc * 100.0))

# make a prediction for a new image.
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.preprocessing.image import img_to_array
from keras.models import load_model

# load and prepare the image
def load_image(filename):
  img = Image.open(filename).resize((224, 224))
  plt.imshow(img)
  plt.show()
  img = load_img(filename, target_size=(28, 28))
  img = img_to_array(img)
  img = img[:,:,0]
  img = img.reshape(1,28, 28, 1)
  img = img.astype('float32')
  img = img / 255.0
  return img

def run_example(filename):
  img = load_image(filename)
  model = load_model('/content/drive/MyDrive/Models/saved_fashion.h5')
  result = np.argmax(model.predict(img), axis=1)
  if result == 0:
    print('Tshirt')
  elif result == 1:
    print('Top')
  elif result == 2:
    print('Pullover')
  elif result == 3:
    print('Dress')
  elif result == 4:
    print('Coat')
  elif result == 5:
    print('Sandal')
  elif result == 6:
    print('Shirt')
  elif result == 7:
    print('Snicker')
  elif result == 8:
    print('Bag')
  else:
    print('Ankle Boot')



